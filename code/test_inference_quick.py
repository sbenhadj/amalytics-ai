"""
Test rapide de validation - ne charge PAS de mod√®les.
V√©rifie uniquement que la structure du code est correcte.
"""

import json
import sys
from pathlib import Path

# Ajouter src/ au path
ROOT_DIR = Path(__file__).resolve().parent
SRC_DIR = ROOT_DIR / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))


def test_imports():
    """Test que tous les modules sont importables (sans charger de mod√®les)."""
    print("=" * 70)
    print("TEST 1: Import des modules")
    print("=" * 70)
    
    try:
        from amalytics_ml.config import InferenceConfig
        print("‚úÖ InferenceConfig import√©")
        
        # Test d'import de la structure (pas d'ex√©cution)
        from amalytics_ml.models.inference import InferenceResult
        print("‚úÖ InferenceResult import√©")
        
        from amalytics_ml.utils.template_split import (
            split_template_by_measurements,
            deep_merge,
        )
        print("‚úÖ Fonctions de split import√©es")
        
        from amalytics_ml.data.anonymization import (
            AnonymizationConfig,
            anonymize_text,
        )
        print("‚úÖ Fonctions d'anonymisation import√©es")
        
        return True
    except Exception as e:
        print(f"‚ùå Erreur d'import: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_config():
    """Test la cr√©ation de configuration."""
    print("\n" + "=" * 70)
    print("TEST 2: Cr√©ation de configuration")
    print("=" * 70)
    
    try:
        from amalytics_ml.config import InferenceConfig
        
        config = InferenceConfig(
            model_path="test/model",
            lora_path="test/lora",
            apply_anonymization=False,
            use_batch_inference=False,
        )
        
        print(f"‚úÖ Configuration cr√©√©e")
        print(f"   - apply_anonymization: {config.apply_anonymization}")
        print(f"   - use_batch_inference: {config.use_batch_inference}")
        
        config_anon = InferenceConfig(
            model_path="test/model",
            lora_path="test/lora",
            apply_anonymization=True,
            anonymization_use_ner=False,
        )
        
        print(f"‚úÖ Configuration avec anonymisation cr√©√©e")
        print(f"   - apply_anonymization: {config_anon.apply_anonymization}")
        
        config_batch = InferenceConfig(
            model_path="test/model",
            lora_path="test/lora",
            use_batch_inference=True,
            max_measurements_per_batch=3,
        )
        
        print(f"‚úÖ Configuration batch cr√©√©e")
        print(f"   - use_batch_inference: {config_batch.use_batch_inference}")
        
        return True
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_template_split():
    """Test le split de template (sans mod√®le)."""
    print("\n" + "=" * 70)
    print("TEST 3: Split de template")
    print("=" * 70)
    
    try:
        from amalytics_ml.utils.template_split import split_template_by_measurements
        
        test_template = {
            "Hematologie": {
                "NumerationGlobulaire": {
                    "Hematies": {"valeur": None, "unit√©": "T/L"},
                    "Hematocrite": {"valeur": None, "unit√©": "%"},
                }
            }
        }
        
        parts = split_template_by_measurements(
            test_template,
            max_objects_per_part=1,
            dedup_consecutive=True,
        )
        
        print(f"‚úÖ Template split√© en {len(parts)} parties")
        for i, part in enumerate(parts, 1):
            part_str = json.dumps(part, ensure_ascii=False)
            print(f"   - Partie {i}: {len(part_str)} caract√®res")
        
        return True
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_anonymization_text():
    """Test l'anonymisation de texte (sans NER)."""
    print("\n" + "=" * 70)
    print("TEST 4: Anonymisation de texte")
    print("=" * 70)
    
    try:
        from amalytics_ml.data.anonymization import anonymize_text, AnonymizationConfig
        
        test_text = """
        Date de naissance: 15/03/1985
        Email: test@example.com
        T√©l√©phone: 0612345678
        """
        
        config = AnonymizationConfig(
            secret_key=b"test_key",
            use_ner=False,  # D√©sactiver NER pour test rapide
            anonymize_codes=True,
            anonymize_dates=True,
            anonymize_emails=True,
            anonymize_phones=True,
        )
        
        anonymized = anonymize_text(test_text, config)
        print(f"‚úÖ Anonymisation r√©ussie")
        print(f"   - Texte modifi√©: {'Oui' if test_text != anonymized else 'Non'}")
        
        return True
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_pdf_detection():
    """Test la d√©tection de PDF (sans extraction)."""
    print("\n" + "=" * 70)
    print("TEST 5: D√©tection de fichiers PDF")
    print("=" * 70)
    
    # Chercher un PDF de test (sans l'extraire)
    pdf_path = ROOT_DIR.parent / "amalytics-ml" / "data" / "reports" / "sample_1.pdf"
    
    if not pdf_path.exists():
        pdf_path = Path("amalytics-ml/data/reports/sample_1.pdf")
        if not pdf_path.exists():
            print(f"‚ö†Ô∏è  PDF non trouv√© (test ignor√©)")
            return True
    
    try:
        # V√©rifier juste que le fichier existe (pas d'extraction)
        if pdf_path.exists():
            size_kb = pdf_path.stat().st_size / 1024
            print(f"‚úÖ PDF trouv√©: {pdf_path.name}")
            print(f"   - Taille: {size_kb:.1f} KB")
            print(f"   - Path valide: Oui")
            return True
        else:
            print(f"‚ö†Ô∏è  PDF non trouv√©")
            return True
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False


def test_template_loading():
    """Test le chargement de template."""
    print("\n" + "=" * 70)
    print("TEST 6: Chargement de template")
    print("=" * 70)
    
    template_path = ROOT_DIR.parent / "amalytics-ml" / "data" / "filtered_templates" / "empty" / "sample_1_template_empty.json"
    
    if not template_path.exists():
        template_path = Path("amalytics-ml/data/filtered_templates/empty/sample_1_template_empty.json")
        if not template_path.exists():
            print(f"‚ö†Ô∏è  Template non trouv√© (test ignor√©)")
            return True
    
    try:
        with template_path.open("r", encoding="utf-8") as f:
            template = json.load(f)
        
        print(f"‚úÖ Template charg√©: {template_path.name}")
        print(f"   - Cl√©s de premier niveau: {list(template.keys())[:3]}")
        
        # Compter les mesures rapidement
        def count_measurements(obj, count=0):
            if isinstance(obj, dict):
                if "valeur" in obj:
                    return count + 1
                return sum(count_measurements(v, count) for v in obj.values())
            return count
        
        measurements = count_measurements(template)
        print(f"   - Nombre de mesures: {measurements}")
        
        return True
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


def print_summary(results: dict[str, bool]):
    """Affiche le r√©sum√©."""
    print("\n" + "=" * 70)
    print("R√âSUM√â DES TESTS")
    print("=" * 70)
    
    total = len(results)
    passed = sum(1 for v in results.values() if v)
    
    for name, result in results.items():
        status = "‚úÖ PASS√â" if result else "‚ùå √âCHOU√â"
        print(f"{name:.<50} {status}")
    
    print(f"\nTotal: {total} tests | R√©ussis: {passed} ‚úÖ | √âchou√©s: {total - passed} ‚ùå")
    
    if passed == total:
        print("\n" + "üéâ" * 35)
        print("TOUS LES TESTS SONT PASS√âS!")
        print("\n‚úÖ Le code est structurellement correct")
        print("‚úÖ Pr√™t pour Colab avec LLaMA + LoRA")
        print("\nüìã Configuration recommand√©e pour Colab:")
        print("   - model_path: 'meta-llama/Meta-Llama-3.1-8B-Instruct'")
        print("   - lora_path: chemin vers votre LoRA fine-tun√©")
        print("   - apply_anonymization: True (si n√©cessaire)")
        print("   - use_batch_inference: True (pour optimisation)")
        print("   - load_in_4bit: True (pour √©conomiser la m√©moire)")
        print("üéâ" * 35)
        return True
    else:
        print("\n‚ö†Ô∏è  Certains tests ont √©chou√©. Corrigez les erreurs.")
        return False


def main():
    """Ex√©cute tous les tests rapides."""
    print("\n" + "üöÄ" * 35)
    print("TESTS RAPIDES - VALIDATION STRUCTURE")
    print("üöÄ" * 35)
    print("\nCes tests v√©rifient la structure sans charger de mod√®les.\n")
    
    results = {}
    results["Imports"] = test_imports()
    results["Configuration"] = test_config()
    results["Split template"] = test_template_split()
    results["Anonymisation"] = test_anonymization_text()
    results["D√©tection PDF"] = test_pdf_detection()
    results["Chargement template"] = test_template_loading()
    
    all_passed = print_summary(results)
    
    sys.exit(0 if all_passed else 1)


if __name__ == "__main__":
    main()

